{
  "per_question": [
    {
      "id": "academic-standards:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7971267700195312,
      "bertscore_f1": 0.40726107358932495,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7348458170890808,
      "bertscore_f1": 0.1494666188955307,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6240505200038379
    },
    {
      "id": "academic-standards:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6593186855316162,
      "bertscore_f1": 0.2795301675796509,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.6644577980041504,
      "bertscore_f1": 0.4451504051685333,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5759850144386292,
      "bertscore_f1": 0.30889806151390076,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.6469210386276245,
      "bertscore_f1": 0.3781834840774536,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6394520998001099,
      "bertscore_f1": 0.5337495803833008,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6698015332221985,
      "bertscore_f1": 0.2791999578475952,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "academic-standards:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6888430714607239,
      "bertscore_f1": 0.30368927121162415,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8350887298583984,
      "bertscore_f1": 0.5648179054260254,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6839576363563538,
      "bertscore_f1": 0.18656663596630096,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7328286204777911
    },
    {
      "id": "degree-requirements:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6915150284767151,
      "bertscore_f1": 0.278952032327652,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "degree-requirements:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6891253590583801,
      "bertscore_f1": 0.12484310567378998,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6498493552207947,
      "bertscore_f1": 0.08806446939706802,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6732701063156128,
      "bertscore_f1": 0.3055373728275299,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5998521447181702,
      "bertscore_f1": 0.16636507213115692,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "degree-requirements:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7701655626296997,
      "bertscore_f1": 0.3358054757118225,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6463158130645752,
      "bertscore_f1": 0.341644287109375,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.835638701915741,
      "bertscore_f1": 0.503715991973877,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.33827292919158936,
      "bertscore_f1": 0.1817067712545395,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "grading:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.9382408261299133,
      "bertscore_f1": 0.6737684011459351,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8474140763282776,
      "bertscore_f1": 0.29295384883880615,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "grading:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.9112025499343872,
      "bertscore_f1": 0.5668712258338928,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5798434615135193,
      "bertscore_f1": 0.09916011244058609,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8215721845626831,
      "bertscore_f1": 0.42552027106285095,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7751641869544983,
      "bertscore_f1": 0.33244654536247253,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "grading:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7227082848548889,
      "bertscore_f1": 0.263134628534317,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4175501763820648,
      "bertscore_f1": 0.20033042132854462,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4299658238887787,
      "bertscore_f1": 0.03671189397573471,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6384170055389404,
      "bertscore_f1": 0.06229883059859276,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.573013424873352,
      "bertscore_f1": 0.4533063471317291,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.698225200176239,
      "bertscore_f1": 0.28643906116485596,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8575526475906372,
      "bertscore_f1": 0.6993722915649414,
      "recall@1": 0.5,
      "recall@3": 0.5,
      "recall@5": 0.5,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9401460289955139,
      "bertscore_f1": 0.5288798213005066,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "graduation:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7200528383255005,
      "bertscore_f1": 0.42888343334198,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9074373245239258,
      "bertscore_f1": 0.7262447476387024,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.783900260925293,
      "bertscore_f1": 0.6849371194839478,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2547754943370819,
      "bertscore_f1": -0.05037396401166916,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "graduation:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.8028718829154968,
      "bertscore_f1": 0.18619616329669952,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "graduation:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7457920908927917,
      "bertscore_f1": 0.3979905843734741,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6508855223655701,
      "bertscore_f1": 0.16017554700374603,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5437713091520254
    },
    {
      "id": "grading:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.9113497138023376,
      "bertscore_f1": 0.5984399914741516,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.6666666666666666,
      "nugget_f1": 0.8,
      "sbert_cosine": 0.8848845362663269,
      "bertscore_f1": 0.2011561095714569,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9060254355346823
    },
    {
      "id": "credit-transfer:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9013752937316895,
      "bertscore_f1": 0.6589444279670715,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "courses:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5173099040985107,
      "bertscore_f1": 0.006561043206602335,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "degree-requirements:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9791709780693054,
      "bertscore_f1": 0.9158793091773987,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7466750741004944,
      "bertscore_f1": 0.22819136083126068,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8853623270988464,
      "bertscore_f1": 0.7665489912033081,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "degree-requirements:q0013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8222734332084656,
      "bertscore_f1": 0.4354398846626282,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.6666666666666666,
      "nugget_f1": 0.8,
      "sbert_cosine": 0.3520660400390625,
      "bertscore_f1": -0.03830182924866676,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "degree-requirements:q0015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.30128589272499084,
      "bertscore_f1": 0.07198429852724075,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "degree-requirements:q0016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.6348041296005249,
      "bertscore_f1": 0.1732647866010666,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "degree-requirements:q0017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.6469478011131287,
      "bertscore_f1": 0.06932110339403152,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "degree-requirements:q0018",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6291571259498596,
      "bertscore_f1": 0.18657687306404114,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7837592959403992,
      "bertscore_f1": 0.5963994264602661,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.5674028396606445,
      "bertscore_f1": 0.17614765465259552,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8529278650606567
    },
    {
      "id": "admissions:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6074127554893494,
      "bertscore_f1": 0.17251573503017426,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "admissions:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7534305453300476,
      "bertscore_f1": 0.12153857201337814,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.6934264036172708
    },
    {
      "id": "admissions:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6925291419029236,
      "bertscore_f1": 0.035065099596977234,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "admissions:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6696680188179016,
      "bertscore_f1": 0.280576229095459,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "admissions:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7591409087181091,
      "bertscore_f1": 0.16579964756965637,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "campus-life:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6943621039390564,
      "bertscore_f1": 0.09791238605976105,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-support-services:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.35993239283561707,
      "bertscore_f1": -0.04083753004670143,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3413541913032532,
      "bertscore_f1": -0.02968008443713188,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.45742183923721313,
      "bertscore_f1": -0.08834028989076614,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5557451248168945,
      "bertscore_f1": -0.03315131366252899,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4295085072517395,
      "bertscore_f1": -0.1540195792913437,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "fees-financial-support:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7367230653762817,
      "bertscore_f1": 0.1460925042629242,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "fees-financial-support:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4303407073020935,
      "bertscore_f1": 0.031542662531137466,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.48959892988204956,
      "bertscore_f1": 0.05261548236012459,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.595579206943512,
      "bertscore_f1": 0.08753860741853714,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4854765236377716,
      "bertscore_f1": -0.2057885378599167,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    }
  ],
  "summary": {
    "count": 72,
    "nugget_precision": 1.0,
    "nugget_recall": 0.1388888888888889,
    "nugget_f1": 0.16805555555555554,
    "sbert_cosine": 0.6684525393777423,
    "bertscore_f1": 0.2681156679690402,
    "recall@1": 0.7291666666666666,
    "recall@3": 0.8402777777777778,
    "recall@5": 0.8402777777777778,
    "ndcg@1": 0.7361111111111112,
    "ndcg@3": 0.8031160577387324,
    "ndcg@5": 0.796159831149792
  }
}