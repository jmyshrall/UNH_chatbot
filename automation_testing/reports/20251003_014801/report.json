{
  "per_question": [
    {
      "id": "academic-standards:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9422659277915955,
      "bertscore_f1": 0.7227668166160583,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "academic-standards:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6287705302238464,
      "bertscore_f1": 0.1892506629228592,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "academic-standards:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8885769248008728,
      "bertscore_f1": 0.5817605257034302,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "academic-standards:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.6644577980041504,
      "bertscore_f1": 0.4451504051685333,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7838176488876343,
      "bertscore_f1": 0.6554145812988281,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9204674959182739,
      "bertscore_f1": 0.7776167392730713,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6394520998001099,
      "bertscore_f1": 0.5337495803833008,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "academic-standards:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7927711009979248,
      "bertscore_f1": 0.43412718176841736,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8359046578407288,
      "bertscore_f1": 0.41922727227211,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8050589561462402,
      "bertscore_f1": 0.5813992619514465,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6931525468826294,
      "bertscore_f1": 0.15866754949092865,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7606395682357036
    },
    {
      "id": "degree-requirements:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6140571236610413,
      "bertscore_f1": 0.35468021035194397,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.43067655807339306
    },
    {
      "id": "degree-requirements:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.7174957394599915,
      "bertscore_f1": 0.16969962418079376,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5014819502830505,
      "bertscore_f1": -0.011111182160675526,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8094536662101746,
      "bertscore_f1": 0.4323059022426605,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.728844940662384,
      "bertscore_f1": 0.49360954761505127,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7701655626296997,
      "bertscore_f1": 0.3358054757118225,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "degree-requirements:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6463158130645752,
      "bertscore_f1": 0.341644287109375,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.835638701915741,
      "bertscore_f1": 0.503715991973877,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.1885528713464737,
      "bertscore_f1": 0.10728989541530609,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5076245069503784,
      "bertscore_f1": 0.1094576045870781,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "grading:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8555226922035217,
      "bertscore_f1": 0.29423582553863525,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8113538026809692,
      "bertscore_f1": 0.5270557403564453,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.620505154132843,
      "bertscore_f1": 0.19166700541973114,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5896298885345459,
      "bertscore_f1": 0.07252993434667587,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7520995736122131,
      "bertscore_f1": 0.35364967584609985,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7621405720710754,
      "bertscore_f1": 0.36037105321884155,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.7181926369667053,
      "bertscore_f1": 0.4996708631515503,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4280950725078583,
      "bertscore_f1": 0.2034781575202942,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3014259934425354,
      "bertscore_f1": 0.06781027466058731,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "graduation:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5843361020088196,
      "bertscore_f1": 0.35744863748550415,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6138870120048523,
      "bertscore_f1": 0.48434045910835266,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.844635546207428,
      "bertscore_f1": 0.6976181268692017,
      "recall@1": 0.5,
      "recall@3": 0.5,
      "recall@5": 0.5,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.784728467464447,
      "bertscore_f1": 0.12575320899486542,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.767871081829071,
      "bertscore_f1": 0.5609080791473389,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9074373245239258,
      "bertscore_f1": 0.7262447476387024,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "graduation:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7920125722885132,
      "bertscore_f1": 0.7223137021064758,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.34654510021209717,
      "bertscore_f1": 0.2804727554321289,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "graduation:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.8783140182495117,
      "bertscore_f1": 0.34265998005867004,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9047172294870751
    },
    {
      "id": "graduation:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7457920908927917,
      "bertscore_f1": 0.3979905843734741,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.8652074933052063,
      "bertscore_f1": 0.6958099603652954,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "grading:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.9593697190284729,
      "bertscore_f1": 0.8652704954147339,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.6666666666666666,
      "nugget_f1": 0.8,
      "sbert_cosine": 0.765596866607666,
      "bertscore_f1": 0.2870691120624542,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9047172294870751
    },
    {
      "id": "credit-transfer:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.7311669588088989,
      "bertscore_f1": 0.1662227362394333,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "courses:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6905575394630432,
      "bertscore_f1": 0.12484557926654816,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9469024295259745
    },
    {
      "id": "degree-requirements:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4743884205818176,
      "bertscore_f1": 0.036481983959674835,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.8101397156715393,
      "bertscore_f1": 0.29906991124153137,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8853623270988464,
      "bertscore_f1": 0.7665489912033081,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8010597825050354,
      "bertscore_f1": 0.3940824866294861,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.4672304689884186,
      "bertscore_f1": 0.09787636995315552,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9861433506011963,
      "bertscore_f1": 0.9125450849533081,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5059764981269836,
      "bertscore_f1": 0.097402423620224,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.8597341775894165,
      "bertscore_f1": 0.6108313798904419,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0018",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9495833516120911,
      "bertscore_f1": 0.6263373494148254,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6522573232650757,
      "bertscore_f1": 0.3708592653274536,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7729616165161133,
      "bertscore_f1": 0.648590087890625,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "admissions:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.37181738018989563,
      "bertscore_f1": -0.07671031355857849,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "admissions:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3793414831161499,
      "bertscore_f1": 0.016209427267313004,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9197207891481876
    },
    {
      "id": "admissions:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6281435489654541,
      "bertscore_f1": 0.0663248747587204,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6411864757537842,
      "bertscore_f1": 0.07119321078062057,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "admissions:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.48564019799232483,
      "bertscore_f1": 0.057103466242551804,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "campus-life:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7274391651153564,
      "bertscore_f1": 0.16704702377319336,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "academic-support-services:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9324526786804199,
      "bertscore_f1": 0.6983385682106018,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5805839896202087,
      "bertscore_f1": 0.2019055187702179,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6800166964530945,
      "bertscore_f1": 0.1510014683008194,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8311387896537781,
      "bertscore_f1": 0.4737819731235504,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.5012658353418871
    },
    {
      "id": "registration:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5952984690666199,
      "bertscore_f1": 0.042179547250270844,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "fees-financial-support:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.7746872305870056,
      "bertscore_f1": 0.5424345135688782,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7606395682357036
    },
    {
      "id": "fees-financial-support:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.41067519783973694,
      "bertscore_f1": -0.012037171982228756,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "registration:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8372960090637207,
      "bertscore_f1": 0.45660310983657837,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8611123561859131,
      "bertscore_f1": 0.4809423089027405,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8529278650606567
    },
    {
      "id": "registration:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.46885186433792114,
      "bertscore_f1": 0.18736512959003448,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6509209298071326
    }
  ],
  "summary": {
    "count": 72,
    "nugget_precision": 1.0,
    "nugget_recall": 0.16666666666666666,
    "nugget_f1": 0.20324074074074072,
    "sbert_cosine": 0.700017616773645,
    "bertscore_f1": 0.3628607307974663,
    "recall@1": 0.8541666666666666,
    "recall@3": 0.9236111111111112,
    "recall@5": 0.9652777777777778,
    "ndcg@1": 0.8611111111111112,
    "ndcg@3": 0.9014982594697503,
    "ndcg@5": 0.9056620691938119
  }
}