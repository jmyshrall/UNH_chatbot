{
  "per_question": [
    {
      "id": "academic-standards:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9422659277915955,
      "bertscore_f1": 0.7227668166160583,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "academic-standards:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6287705302238464,
      "bertscore_f1": 0.1892506629228592,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "academic-standards:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8885769248008728,
      "bertscore_f1": 0.5817605257034302,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "academic-standards:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.6644577980041504,
      "bertscore_f1": 0.4451504051685333,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7838176488876343,
      "bertscore_f1": 0.6554145812988281,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9204674959182739,
      "bertscore_f1": 0.7776167392730713,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6394520998001099,
      "bertscore_f1": 0.5337495803833008,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "academic-standards:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7366734743118286,
      "bertscore_f1": 0.46126872301101685,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8359046578407288,
      "bertscore_f1": 0.41922727227211,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8050589561462402,
      "bertscore_f1": 0.5813992619514465,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7109341025352478,
      "bertscore_f1": 0.19069191813468933,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7606395682357036
    },
    {
      "id": "degree-requirements:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6140571236610413,
      "bertscore_f1": 0.35468021035194397,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.43067655807339306
    },
    {
      "id": "degree-requirements:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6699671745300293,
      "bertscore_f1": 0.13343341648578644,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.698571503162384,
      "bertscore_f1": 0.05482097715139389,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7710618376731873,
      "bertscore_f1": 0.2656025290489197,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.7534698247909546,
      "bertscore_f1": 0.5580937266349792,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6092371344566345,
      "bertscore_f1": 0.42343589663505554,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "degree-requirements:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6463158130645752,
      "bertscore_f1": 0.341644287109375,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.835638701915741,
      "bertscore_f1": 0.503715991973877,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.297544002532959,
      "bertscore_f1": 0.12223748117685318,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6631989479064941,
      "bertscore_f1": 0.09707857668399811,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "grading:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8026821613311768,
      "bertscore_f1": 0.3004825711250305,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.788433313369751,
      "bertscore_f1": 0.4478086531162262,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6151914000511169,
      "bertscore_f1": 0.08108916878700256,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6385664343833923,
      "bertscore_f1": 0.1719619780778885,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7520995736122131,
      "bertscore_f1": 0.35364967584609985,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7776329517364502,
      "bertscore_f1": 0.35448068380355835,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.7181926369667053,
      "bertscore_f1": 0.4996708631515503,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4280950725078583,
      "bertscore_f1": 0.2034781575202942,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3014259934425354,
      "bertscore_f1": 0.06781027466058731,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "graduation:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5843361020088196,
      "bertscore_f1": 0.35744863748550415,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7233781814575195,
      "bertscore_f1": 0.4095216691493988,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.844635546207428,
      "bertscore_f1": 0.6976181268692017,
      "recall@1": 0.5,
      "recall@3": 0.5,
      "recall@5": 0.5,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9401460289955139,
      "bertscore_f1": 0.5288798213005066,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.767871081829071,
      "bertscore_f1": 0.5609080791473389,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.8589174151420593,
      "bertscore_f1": 0.3737732172012329,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "graduation:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8822484016418457,
      "bertscore_f1": 0.8323239684104919,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4943007230758667,
      "bertscore_f1": 0.37528544664382935,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "graduation:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.8783140182495117,
      "bertscore_f1": 0.34265998005867004,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9047172294870751
    },
    {
      "id": "graduation:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7457920908927917,
      "bertscore_f1": 0.3979905843734741,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.8652074933052063,
      "bertscore_f1": 0.6958099603652954,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "grading:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.9109643697738647,
      "bertscore_f1": 0.573133111000061,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.6666666666666666,
      "nugget_f1": 0.8,
      "sbert_cosine": 0.8391150832176208,
      "bertscore_f1": 0.5116758942604065,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9047172294870751
    },
    {
      "id": "credit-transfer:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.8653944134712219,
      "bertscore_f1": 0.36170247197151184,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "courses:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6905575394630432,
      "bertscore_f1": 0.12484557926654816,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9469024295259745
    },
    {
      "id": "degree-requirements:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.512850821018219,
      "bertscore_f1": 0.08424608409404755,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.797336757183075,
      "bertscore_f1": 0.2426236867904663,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8853623270988464,
      "bertscore_f1": 0.7665489912033081,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8521187901496887,
      "bertscore_f1": 0.32413381338119507,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.4075621962547302,
      "bertscore_f1": 0.1077924445271492,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9861433506011963,
      "bertscore_f1": 0.9125450849533081,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7984998226165771,
      "bertscore_f1": 0.4171757400035858,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.8200488686561584,
      "bertscore_f1": 0.5348906517028809,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0018",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9015151858329773,
      "bertscore_f1": 0.5864335894584656,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5901663303375244,
      "bertscore_f1": 0.6257984042167664,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7374657392501831,
      "bertscore_f1": 0.5146622061729431,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "admissions:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3843260407447815,
      "bertscore_f1": -0.016423797234892845,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "admissions:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.9329382181167603,
      "bertscore_f1": 0.6208354234695435,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9197207891481876
    },
    {
      "id": "admissions:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4015149772167206,
      "bertscore_f1": -0.03713074326515198,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7726231813430786,
      "bertscore_f1": 0.16196537017822266,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "admissions:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.48564019799232483,
      "bertscore_f1": 0.057103466242551804,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "campus-life:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.6969996094703674,
      "bertscore_f1": 0.13705120980739594,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "academic-support-services:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8130292296409607,
      "bertscore_f1": 0.39756712317466736,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5805839896202087,
      "bertscore_f1": 0.2019055187702179,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.6989469528198242,
      "bertscore_f1": 0.12575215101242065,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8638343214988708,
      "bertscore_f1": 0.5389078259468079,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.5012658353418871
    },
    {
      "id": "registration:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5196999311447144,
      "bertscore_f1": 0.07301093637943268,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "fees-financial-support:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8161234855651855,
      "bertscore_f1": 0.4832463562488556,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7606395682357036
    },
    {
      "id": "fees-financial-support:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3841327726840973,
      "bertscore_f1": 0.0010866794036701322,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "registration:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.761216402053833,
      "bertscore_f1": 0.360935777425766,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9120236039161682,
      "bertscore_f1": 0.6023572683334351,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8529278650606567
    },
    {
      "id": "registration:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5837839245796204,
      "bertscore_f1": 0.21241985261440277,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6509209298071326
    }
  ],
  "summary": {
    "count": 72,
    "nugget_precision": 1.0,
    "nugget_recall": 0.16898148148148145,
    "nugget_f1": 0.20787037037037034,
    "sbert_cosine": 0.7184087046318584,
    "bertscore_f1": 0.37603457317487077,
    "recall@1": 0.8541666666666666,
    "recall@3": 0.9236111111111112,
    "recall@5": 0.9652777777777778,
    "ndcg@1": 0.8611111111111112,
    "ndcg@3": 0.9014982594697503,
    "ndcg@5": 0.9056620691938119
  }
}